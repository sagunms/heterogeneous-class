MP5: Parallel Scan
===================

Objective
---------

Implement a kernel the performs parallel scan on a 1D list. The scan operator
used will be addition. You should implement the work efficient kernel in
Lecture 6.3. Your kernel should be able to handle input lists of arbitrary
length. However, for simplicity, you can assume that the input list will be at
most 2048 * 65,535 elements so that it can be handled by only one kernel
launch. The boundary condition can be handled by filling "identity value (0 for
sum)" into the shared memory of the last block when the length is not a
multiple of the thread block size.

Prerequisites
-------------

Before starting this lab, make sure that:

1. You have completed MP4
2. You can have completed lecture 6.1 through 6.3

Instructions
------------

Edit the code in the code tab to perform the following:

* allocate device memory
* copy host memory to device
* initialize thread block and kernel grid dimensions
* invoke CUDA kernel
* copy results from device to host
* deallocate device memory
* implement the work efficient scan routine
* use shared memory to reduce the number of global accesses, handle the
boundary conditions in when loading input list elements into the shared memory

Instructions about where to place each part of the code is demarcated by the
```//@@``` comment lines.

Questions
---------

These are questions that you are encouraged to think about. You will not be
graded on them, however, so feel free to attempt them and discuss them on the
forum.

* Describe how you handled arrays not a power of two in size, how you minimized
  shared memory bank conflicts, and any other performance-enhancing
  optimizations you added.
* What is the FLOPS rate for the GPU kernel?
* Name two applications of scan.
* In both scan and reduction, the operator used was the Plus operator. What
  would happen if we use a Subtract operator?
* What is the minimum, maximum, and average number of "real" operations that a
  thread will perform? "Real" operations are those that directly contribute to
  the final reduction value.
* How many times does your thread block synchronize?
* Compare the mapping of thread indices to data indices in the work efficient
  scan kernel versus the reduction kernel. Explain why both have similar control
  divergence behavior.

Grading
-------

You will be grading based on the following rubric:

* Compilation (no warning): 5%
* Run time (with respect to other students): 15%
* Correctness (generates correct values, follows objective, and deals with
  boundary conditions correctly): 80%

If we cannot compile your program, then you will get 0 points. Note that we only
grade the last program submitted and do not accept programs beyond the deadline.

For the run time grade, we will take the average time of all the final
submissions. If your time is no more than 10% above the average time, then you
will get full marks. Otherwise, you will lose points.

Note that the datasets that we test against are not the same as the ones
provided, so make sure to code the algorithm for correctness on general datasets
not just the ones provided.

Suggestions
-----------

* Develop your application incrementally
* Check for CUDA errors, here is some example ```wbCheck``` that you can use
  (included in the template code). using this in your code would look like
  ```wbCheck(cudaMalloc(...))```

        #define wbCheck(stmt)                                       \
            do {                                                    \
                cudaError_t err = stmt;                             \
                if (err != cudaSuccess) {                           \
                    wbLog(ERROR, "Failed to run stmt ", #stmt);     \
                    return -1;                                      \
                }                                                   \
            } while(0)

* Make sure that your algorithm handles boundary conditions where the size of
  the matrix may not be a multiple of the block/tile size
* Make sure that your algorithm handles rectangular matrices, not just square
  matrices as shown in the slides
* Do not modify the template code written -- only insert code where the
  ```//@@``` demarcation is placed
* Do not wait until the last minute to attempt the lab
* Make sure that you test your program using all the datasets provided (the
  datasets can be selected using the dropdown next to the submission button)
* Even though you can submit multiple times, only your last submission is graded


